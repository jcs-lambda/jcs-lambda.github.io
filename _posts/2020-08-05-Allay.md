---
layout: post
title: Allay
gh-repo: jcs-lambda/allay-ds
gh-badge: [star, fork, follow]
tags: [lambda, data science, machine learning]
comments: false
---

I was fortunate to be included as part of a cross-functional team to move the Allay
project closer to production. Allay will be a social network for [Lambda School](https://lambdaschool.com)
students and alumni to make connections and be better informed about the hiring process.

[Alex Jenkins-Neary](http://www.alexjenkinsneary.com), [Andrew Archie](https://www.linkedin.com/in/andrew-archie-04b24b1a9), and I made up the data science team. We sourced training data, evaluated several
model types, and deployed an API to provide ML assisted content moderation features to Allay administrators.

Details about our contributions to the project can be found in my archived fork 
of the work we completed [on Github](https://github.com/jcs-lambda/allay-ds).

## Team Work
Coming together to work with several people on a new to us project involved a lot of planning.
We spent the first two weeks getting to know each other while deciding the specifics of our product vision.
Our product vision document and release canvases were laid out in Notion documents that defined the roadmap
for both sprints we would work together.

That roadmap proved invaluable as we broke each release canvas into specific tasks.
Defining tasks in terms of user stories and tracking the progress on our Trello board was key in
ensuring that we were moving as a team towards achieving the goals we had set for ourselves.

## Machine Learning
The data science team started from scratch in our contribution to the project. We decided to provide
a machine learning model able to bring potentially inappropriate content to the attention
of Allay moderators, saving them time while keeping the content posted to the site relevant and helpful to the users.

We worked together on [cleaning and exploring](https://github.com/jcs-lambda/allay-ds/tree/master/exploration) the [training data](https://github.com/jcs-lambda/allay-ds#data-sources) that Alex sourced.
Alex also setup a model evaluation and hyper-parameter tuning framework using [Weights and Biases](https://www.wandb.com) that we all used to explore the different model types we considered. Andrew developed a model
to generate data for additional testing and model evaluation. The CNN I implemented using Tensorflow, based on [this paper](https://arxiv.org/abs/1510.03820) by Ye Zhang and Byron Wallace, was our
best performing model which I deployed as a FastAPI app to Heroku.

## What I Learned
Preparation is key! The planning phase was longer than I anticipated, but the way the team
worked together to define clear goals and how to reach them ensured there was always a way
forward throughout the process.
